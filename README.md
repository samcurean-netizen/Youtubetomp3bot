# Telegram Audio Bot

A powerful Telegram bot that handles YouTube audio downloads and local speech-to-text transcription.

## Features

- üéµ **YouTube to MP3**: Send a YouTube link and get an MP3 file back
- üé§ **Audio Transcription**: Send voice messages or audio files for local transcription
- üíæ **Smart Storage**: Configurable file deletion after processing
- üë• **Group Support**: Works in private chats and groups with admin controls
- üîí **Privacy First**: All transcription happens locally - no external APIs needed
- üìä **Database Tracking**: Prevents duplicate processing of messages and audio files
- ‚òÅÔ∏è **Flexible Deployment**: Run with polling (VPS) or webhooks (Pipedream, serverless)

## Deployment Options

This bot supports two deployment modes:

1. **Polling Mode** (Traditional) - `main.py`
   - Continuously runs on a server (VPS, Replit, etc.)
   - Uses long polling to fetch updates from Telegram
   - Includes Flask keep-alive server
   - Best for: VPS, dedicated servers, always-on platforms

2. **Webhook Mode** (Serverless) - `pipedream_handler.py`
   - Event-driven, runs only when triggered
   - Works on serverless platforms like Pipedream
   - No keep-alive server needed
   - Best for: Serverless deployments, lower costs, scalability
   
   üìö **Quick Links:**
   - [5-Minute Pipedream Setup](QUICKSTART_PIPEDREAM.md)
   - [Full Deployment Guide](PIPEDREAM_DEPLOYMENT.md)
   - [Polling vs Webhook Comparison](POLLING_VS_WEBHOOK.md)
   - [Architecture Overview](ARCHITECTURE.md)

## Requirements

- Python 3.11+
- FFmpeg (for audio processing)
- Telegram Bot Token

## Installation

1. Clone the repository:
```bash
git clone <repository-url>
cd <repository-directory>
```

2. Install dependencies:
```bash
pip install -r requirements.txt
# or using uv (recommended):
uv pip install -e .
```

3. Install FFmpeg (if not already installed):
```bash
# Ubuntu/Debian
sudo apt-get install ffmpeg

# macOS
brew install ffmpeg

# Windows
# Download from https://ffmpeg.org/download.html
```

4. Set up your Telegram Bot Token:
   - Talk to [@BotFather](https://t.me/botfather) on Telegram
   - Create a new bot or use an existing one
   - Copy the bot token

5. Set the environment variable:
```bash
export BOT_TOKEN="your-telegram-bot-token-here"
```

Or create a `.env` file (if using a tool that loads it):
```
BOT_TOKEN=your-telegram-bot-token-here
```

## Usage

### Running the Bot

```bash
python main.py
```

The bot will start and be accessible on Telegram. It also runs a Flask keep-alive server on port 8080.

### Bot Commands

- `/start` - Initialize the bot and see available features

### Features

#### YouTube to MP3
Simply send a YouTube URL to the bot (works in private chats or groups):
```
https://www.youtube.com/watch?v=example
```

The bot will:
1. Download the audio from YouTube
2. Convert it to MP3 format
3. Send the MP3 file back to you
4. Optionally delete the file based on your settings

#### Audio Transcription
Send any voice message or audio file to the bot, and it will:
1. Download the audio file
2. Transcribe it using a local Whisper model (no API calls!)
3. Send back the transcribed text with detected language
4. Optionally delete the file based on your settings

Supported audio formats:
- `.mp3`, `.mp4`, `.mpeg`, `.mpga`, `.m4a`
- `.wav`, `.webm`, `.ogg`, `.oga`
- Voice messages

#### Settings Management

Admins can control whether files are deleted after processing:

1. When you first start the bot, admins will be asked about file deletion preferences
2. To change settings later, send: `change` (or `@botname change` in groups)
3. The bot will toggle between keeping and deleting files

## Architecture

### Components

- **main.py**: Core bot logic, handlers, and Flask keep-alive server
- **database.py**: SQLite database for settings and processed message tracking
- **transcription.py**: Local audio transcription using faster-whisper

### Database Schema

The bot uses SQLite to store:
- Chat settings (deletion preferences, admin prompts)
- Processed message IDs (prevents duplicate handling)
- Processed audio file IDs (prevents reprocessing)

### Transcription Technology

The bot uses [faster-whisper](https://github.com/guillaumekln/faster-whisper), a reimplementation of OpenAI's Whisper model using CTranslate2:

- **Model**: Base model (good balance of speed and accuracy)
- **Compute**: CPU with int8 quantization for efficiency
- **Privacy**: All processing happens locally - no data sent to external APIs
- **Speed**: Significantly faster than the original Whisper implementation
- **First Run**: The model will be downloaded automatically on first use (~150MB)

## Configuration

### Environment Variables

- `BOT_TOKEN` (required): Your Telegram bot token from BotFather

### Model Selection

The transcription module uses the `base` model by default. You can modify this in `transcription.py`:

```python
# In _get_model() function:
WhisperModel("base", ...)  # Options: tiny, base, small, medium, large
```

Model comparison:
- **tiny**: Fastest, less accurate (~75MB)
- **base**: Good balance (~150MB) - **Default**
- **small**: More accurate (~500MB)
- **medium**: High accuracy (~1.5GB)
- **large**: Best accuracy (~3GB)

## Development

### Project Structure

```
.
‚îú‚îÄ‚îÄ main.py                      # Main bot application (polling mode)
‚îú‚îÄ‚îÄ pipedream_handler.py         # Webhook handler for Pipedream
‚îú‚îÄ‚îÄ database.py                  # Database operations
‚îú‚îÄ‚îÄ transcription.py             # Audio transcription module
‚îú‚îÄ‚îÄ pyproject.toml               # Project dependencies
‚îú‚îÄ‚îÄ PIPEDREAM_DEPLOYMENT.md      # Webhook deployment guide
‚îú‚îÄ‚îÄ setup_webhook.sh             # Webhook setup script
‚îî‚îÄ‚îÄ bot_data.db                  # SQLite database (created at runtime)
```

### Running in Development

The bot is designed to run continuously. For development on platforms like Replit:
- The Flask server on port 8080 helps keep the bot alive
- The server responds to health checks with "Bot is running!"

### Testing

Send test messages to your bot:
1. YouTube URLs for download testing
2. Voice messages for transcription testing
3. Admin commands in groups to test settings

## Deployment

### Option 1: Pipedream (Webhook Mode) - Recommended for Serverless ‚òÅÔ∏è

Deploy on Pipedream for free serverless hosting with automatic scaling:

1. Create a Pipedream workflow with HTTP trigger
2. Copy code from `pipedream_handler.py` into a Python step
3. Set `BOT_TOKEN` in environment variables
4. Deploy and copy the webhook URL
5. Run the setup script:
   ```bash
   ./setup_webhook.sh
   ```

**Advantages:**
- Free tier with generous limits
- Automatic scaling
- No server maintenance
- Pay only for what you use

üìö **[Full Pipedream Deployment Guide](PIPEDREAM_DEPLOYMENT.md)**

### Option 2: Replit/Cloud Platforms (Polling Mode)

1. Fork the repository to your platform
2. Set the `BOT_TOKEN` secret/environment variable
3. Run the bot with `python main.py`

The Flask keep-alive server will help prevent the bot from sleeping on free tiers.

### Option 3: VPS/Dedicated Server (Polling Mode)

1. Clone the repository
2. Set up a systemd service or use screen/tmux
3. Ensure FFmpeg is installed
4. Set environment variables
5. Run the bot

Example systemd service:
```ini
[Unit]
Description=Telegram Audio Bot
After=network.target

[Service]
Type=simple
User=youruser
WorkingDirectory=/path/to/bot
Environment="BOT_TOKEN=your-token-here"
ExecStart=/usr/bin/python3 main.py
Restart=always

[Install]
WantedBy=multi-user.target
```

## Troubleshooting

### Model Download Issues
If the Whisper model fails to download:
- Ensure you have a stable internet connection on first run
- Check disk space (models can be 150MB - 3GB depending on size)
- The model is cached after first download

### FFmpeg Not Found
Install FFmpeg for your platform (see Installation section).

### Transcription Quality
- For better accuracy, use a larger model (edit `transcription.py`)
- Ensure audio quality is good (clear speech, minimal background noise)
- Specify language if known: `transcribe_audio(path, language="en")`

### Memory Usage
- The base model uses ~500MB RAM during transcription
- Larger models require more memory
- Consider using `tiny` model on limited hardware

## License

[Add your license here]

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## Documentation

### üìö Complete Documentation Index

- **[DOCS_INDEX.md](DOCS_INDEX.md)** - Complete documentation index and navigation guide

### Quick Links

- **[5-Minute Quick Start](QUICKSTART_PIPEDREAM.md)** - Get bot running on Pipedream in 5 minutes
- **[Full Pipedream Guide](PIPEDREAM_DEPLOYMENT.md)** - Comprehensive webhook deployment guide
- **[Polling vs Webhook](POLLING_VS_WEBHOOK.md)** - Comparison and decision guide
- **[Architecture](ARCHITECTURE.md)** - System design and technical details
- **[Setup Summary](WEBHOOK_SETUP_SUMMARY.md)** - Implementation overview and checklist

## Acknowledgments

- [python-telegram-bot](https://github.com/python-telegram-bot/python-telegram-bot) - Telegram Bot API wrapper
- [faster-whisper](https://github.com/guillaumekln/faster-whisper) - Fast Whisper implementation
- [yt-dlp](https://github.com/yt-dlp/yt-dlp) - YouTube downloader
- [OpenAI Whisper](https://github.com/openai/whisper) - Original Whisper model
- [Pipedream](https://pipedream.com) - Serverless platform for webhook deployment
